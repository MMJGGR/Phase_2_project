Schedule
Saturday - Monday: Work separately on projects on individual notebooks.
Tuesday - discuss best models, select models and work on final notebook
Wednesday - work on final presentation and review project
Thursday - submit final project

Notebook Structure:
1. ○ Introduction (craft an appropriate overview and business understanding using the business problem).
			 Overview
			 Business understanding & objectives
		○ Data understanding
			 Explain the data in a paragraph or two 
			 Import necessary libraries
			 Load dataset into dataframe
			 Inspect the dataframe (df.shape; df.info; df.description etc) and 
			 comment on the data
			
		○ EDA & Data Cleaning 
			 Drop/Fill null values, 
			 Check and remove Duplicates, 
			 Check for outliers and remove them
			
		○ Data Preparation
			 Feature inspection (use e.g. scatter matrix, histograms, pairplot, heatmap)
			 Select Relevant Columns (comment on why each feature is selected and cross-validate them with e.g., scatter matrix, pairplot, heatmap etc ) 
			 Clean relevant columns further if necessary 
			 Check for regression assumptions
			
		○ Modelling - perform iterative modelling by selecting different features. Build 2-3 models and comment on them based on regression metrics such as mean absolute error (mae) and r-squared. (NB: You can first build a simple regression model with the best feature, then add the second with two features, and then the third with three features and compare them)
			 Define X and y (Separate Feature & Target)
			 Test-Train Split; 
			 Scale data if necessary (standardscaler)
			 model=Linear Regression()
	
		○ Validation (Regression Results); use at least 2 important parameter estimates or statistics. For example.
			 Mean absolute error
			 RMSE
			 r-squared
			 Feature coefficients
			 Discuss the best model and why it is the best in 1 - 3 paragraphs.
			
		○ Conclusions based on business objectives.
			 Make recommendation that are in line with the business objectives.

Project Structure
1. Introduction
2. Problem Statement
3. Objectives
4. Analysis
5. Conclusion


Business Strategy Implications
Given these insights, the Real Estate Development Company should consider the following strategies:

Target Larger Houses: Since the model indicates that house price increases with the square footage of living space, the company should focus on acquiring or developing larger houses to maximize potential sales prices.

Focus on High-Grade Houses: Houses with higher grades are significantly associated with higher prices. The company should aim to develop or invest in properties with higher quality finishes, better construction, and more desirable features.

Investigate Bathroom Anomaly: The negative coefficient for bathrooms is unusual and suggests a deeper investigation is needed. The company should look into whether this result is due to multicollinearity or other factors not captured in the model. It may be beneficial to re-examine the quality or location of properties with many bathrooms.

Consider Additional Predictors: Since the R-squared value is 0.537, there are other factors influencing house prices that are not included in this model. The company should consider incorporating additional relevant variables such as location, lot size, view, and age of the house to improve the model's predictive power.

Use Predictive Analytics for Targeted Marketing: By using the model to predict high-priced houses, the company can create targeted marketing strategies to attract high-end buyers. This can involve highlighting the features that are most strongly associated with higher prices, such as larger living spaces and higher grades.

Price Optimization: The company can use the model's predictions to set competitive yet profitable prices for their properties, ensuring that they are priced appropriately based on their characteristics.


Based on the OLS regression results and the business context of the Real Estate Development Company venturing into the King County Housing market, several conclusions can be drawn from the data:

Conclusions
Significant Predictors of House Prices:

Square Footage of Living Space (sqft_living): The coefficient suggests that for each additional square foot of living space, house prices are estimated to increase by $203.17, holding other variables constant. This indicates that larger houses tend to command higher prices.

Grade of the House (grade): A higher grade is associated with higher house prices, with each unit increase in grade estimated to increase house prices by $104,600, holding other variables constant. Grades typically reflect the quality and features of the house, influencing buyer preferences and willingness to pay.

Number of Bathrooms (bathrooms): Contrary to initial expectations, the coefficient suggests that each additional bathroom is associated with a decrease in house prices by $38,360, holding other variables constant. This unexpected finding may warrant further investigation into potential factors influencing this relationship.

Model Fit and Statistical Significance:

The overall model has an R-squared value of 0.537, indicating that approximately 53.7% of the variance in house prices can be explained by the predictors (sqft_living, grade, bathrooms) included in the model. This suggests that while these predictors are significant, there are other factors not captured by the model that also influence house prices.

The F-statistic is very high (8359) with a low p-value (0.00), indicating that the model is statistically significant. This implies that at least one of the predictors is significantly related to house prices, reinforcing the reliability of the model's predictions.

Residual Analysis:

The Omnibus and Jarque-Bera tests indicate that the residuals are not normally distributed, which may suggest departures from the assumption of normality in the model. This could impact the reliability of the model's predictions, particularly in the extremes of the price distribution.

The Durbin-Watson statistic (1.980) suggests no significant autocorrelation among residuals, indicating that the model adequately captures the independence assumption of residuals.